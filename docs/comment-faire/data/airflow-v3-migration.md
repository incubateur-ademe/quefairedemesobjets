# Migration airflow v3

## ğŸ—ºï¸ Contexte

- On utilise actuellement Airflow v2 alors que v3 est disponible depuis le 22 avril 2025

## ğŸ’¡Pourquoi migrer?

Autre raison Ã©vidente que v3 doit Ãªtre mieux que v2 sur le long terme:

- ğŸ **Correctif pour bug limitant le clustering**: [voir rapport du bug corrigÃ© en v3](https://github.com/apache/airflow/discussions/46475), ceci fait rÃ©fÃ©rence Ã  la limitation clustering oÃ¹ on ne peut pas dÃ©finir un ordre prÃ©cis pour lâ€™enrichissement
- ğŸ”¢ **Versionnage des DAGs**: on a eu des cas par le passÃ© de regressions sur nos DAG qui bloquaient le mÃ©tier, le mÃ©tier pourra via la UI rÃ©trograder Ã  une version antÃ©rieur qui fonctionne sans avoir Ã  attendre une mise en prod
- ğŸ’½ **La vue dâ€™ensemble assets:** ([datasets](https://airflow.apache.org/docs/apache-airflow/2.10.5/authoring-and-scheduling/datasets.html) en v2) qui devient maintenant partie intÃ©grale de la UI (avant cachÃ© dans le menu supÃ©rieur) et qui va permettre dâ€™avoir une **vue data-centrique (= QUOI)** de notre orchestration plus importantes que les dÃ©tails techniques des DAGs (= COMMENT), notamment pour **aider le mÃ©tier Ã  comprendre** la data quâ€™on gÃ¨re ET **faciliter la gestion des dÃ©pendances entre DAGs**
- ğŸš€ **Une UI plus responsive** (via AJAX qui ne recharge pas tout) pour Ãªtre plus productif

## ğŸ—ï¸ Comment migrer

Recommendation:

1. âœ… **Tests de bout en bout (e2e):** prendre le temps (ex: 1 semaine) pour Ã©crire des tests en bout-en-bout sur les DAG eux-mÃªme
    - [Voir exemple](https://github.com/incubateur-ademe/quefairedemesobjets/tree/main/dags_unit_tests/e2e)
    - A chacune des Ã©tapes suivante on pourra rejouer les tests e2e et confirmer la non-regression de lâ€™ensemble des DAGs
2. ğŸ”Œ **Migrer vers lâ€™API [TaskFlow](https://airflow.apache.org/docs/apache-airflow/stable/tutorial/taskflow.html)**: pour **rÃ©duire la quantitÃ© de code existante** et se prÃ©parer Ã  lâ€™avenir
    - ex: actuellement avec PythonOperator **on doit gÃ©rer les XCOM manuellement** ce qui nâ€™est pas le cas en TaskFlow
3. ğŸ“‚ **Restructurer les dossiers** de la maniÃ¨re suivante: ceci notamment pour rÃ©duire les temps de crawl de lâ€™intÃ©gralite du dossier DAG et mieux organiser le code

    ```bash
    pipelines/
        dags/ # uniquement les fichiers pure DAGs
    	tasks/ # tÃ¢ches rÃ©utilisÃ©es par les DAGs
    	business/ # logique business
    	# autres dossiers Airflow (ex: logs/)
    	tests/
    	    setup/ # ex: compatibilitÃ© pandas vs. SQLAlchemy vs. scikitlearn
    	    e2e/
    	    unit/
    	    performance/ # comparer perfs diffÃ©rentes mÃ©thodes (ex: pytest-benchmark)
    ```

4. ğŸ‹ **Utiliser la nouvelle image docker v3** en montant uniquement `pipelines/dags` sur `$AIRFLOW_HOME/dags`