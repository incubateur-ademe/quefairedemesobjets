# üìä Plateforme de donn√©es

```{toctree}
:hidden:

ingestion-de-source.md
flux-dbt.md
flux-enrich.md
```

Ce projet contient l'environnement d'execution d'Airflow

Les fichiers qui concerne la plateforme data :

- `pyproject.toml` d√©finition des d√©pendances dans la section [dependency-groups]
- `./dags` r√©pertoire dans lequels sont stock√©s tous les dags execut√©s sur le cluster Airflow
- `airflow-scheduler.Dockerfile` et `airflow-webserver.Dockerfile`, fichier de configuration docker executer dans tous les environnements
- `docker-compose.yml` orchestre les dockers en envronnemnt de d√©veloppement
- `./dags/tests` r√©pertoire qui contient les tests des dags

## Environnements

On distingue 3 environements:

- `development` : airflow tourne localement en utilisant l'orchestrateur `docker compose` (cf. [docker-compose.yml](../../../docker-compose.yml))
- `preprod` et `prod` : Airflow tourne sur Scaleway

## Mise √† jour du scheduler et du webserver sur Scaleway

Airflow utilise l'offre CaaS (Container as a Service) de Scaleway, chaque environnement est d√©ploy√© dans un `namespace`:

- lvao-preprod
- lvao-prod

Dans chaque environnement, 2 conteneurs sont d√©ploy√©s:

- lvao-airflow-scheduler : scheduler d'airflow, orchestre et execute les dags car l'option `LocalExecutor` est active
- lvao-airflow-webserver : interface d'airflow

Chaque environnement utilise sa propre base de donn√©es :

- lvao-preprod-airflow
- lvao-prod-airflow

et chaque environnement utilise son espace de stockage s3 :

- lvao-preprod-airflow
- lvao-prod-airflow

## D√©ploiement et configuration

### CI/CD

la platefome Data est d√©ploy√©e en preprod √† chaque mise √† jour de la branche `main` sur Github (cf. [cd.yml](../../../.github/workflows/cd.yml))

Et en production √† chaque depot de tag de version (cf. [cd_prod.yml](../../../.github/workflows/cd.yml))

De la m√™me mani√®re que l'interface, cela permet de garder la coh√©rance entre l'application web et la plateforme data

### Configuration du cluster Airflow

#### Variable d'environnement du cluster Airflow

Les variables d'environnement sont d√©ploy√©s lors de l'ex√©cution des recettes terraform.

Un exemple √† adapter selon l'environnement est disponible sur le fichier [.env.templates](../../../dags/.env.template)

#### Gestion des logs

Pour que les logs du scheduler soient stock√©s sur S3, les instances Scaleway sont lanc√©s avec les variables d'environnement:

```
AIRFLOW__LOGGING__REMOTE_LOGGING=true
AIRFLOW__LOGGING__REMOTE_BASE_LOG_FOLDER=s3://qfdmo-airflow-logs
AIRFLOW__LOGGING__REMOTE_LOG_CONN_ID=s3logs
AIRFLOW__LOGGING__ENCRYPT_S3_LOGS=false
```

`s3logs` est une connection configur√© dans l'interface d'Airflow

Attention √† ajouter le param√®tre endpoint_url pour le stockage S3 de Scaleway
