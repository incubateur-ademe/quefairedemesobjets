import logging

from airflow import DAG
from airflow.operators.python import PythonOperator
from cluster.tasks.business_logic.cluster_acteurs_db_data_read_acteurs import (
    cluster_acteurs_db_data_read_acteurs,
)
from cluster.tasks.business_logic.cluster_acteurs_df_sort import cluster_acteurs_df_sort
from utils import logging_utils as log
from utils.django import django_setup_full

django_setup_full()

from qfdmo.models import DisplayedActeur  # noqa: E402

logger = logging.getLogger(__name__)


def task_info_get():
    return """


    ============================================================
    Description de la t√¢che "cluster_acteurs_db_data_read_acteurs"
    ============================================================

    üí° quoi: va chercher en base de donn√©es les acteurs correspondants
        aux crit√®res d'inclusion et d'exclusion du DAG
         - ces acteurs "candidats" ne seront pas forc√©ment utilis√©s
         dans des clusters

    üéØ pourquoi: c'est la donn√©e de base dont on a besoin pour le clustering

    üèóÔ∏è comment: constructions/execution d'une requ√™te SQL sur la base
        des critr√®res d'inclusion/exclusion
    """


def cluster_acteurs_db_data_read_acteurs_wrapper(**kwargs) -> None:
    logger.info(task_info_get())

    # use xcom to get the params from the previous task
    params = kwargs["ti"].xcom_pull(
        key="params", task_ids="cluster_acteurs_config_validate"
    )

    # Boucle pour automatiser l'affichage des param√®tres de champs
    # et la construction d'un set de tous les champs (pour requ√™te SQL)
    fields = ["source_id", "acteur_type_id", "nom"]
    for key, value in params.items():
        if key.startswith("include_") or key.startswith("exclude_"):
            log.preview(key, value)
        if "fields" in key:
            fields.extend(value or [])
    fields = sorted(list(set(fields)))
    log.preview("Tous les champs reseign√©s", fields)

    df, query = cluster_acteurs_db_data_read_acteurs(
        model_class=DisplayedActeur,
        include_source_ids=params["include_source_ids"],
        include_acteur_type_ids=params["include_acteur_type_ids"],
        include_only_if_regex_matches_nom=params["include_only_if_regex_matches_nom"],
        include_if_all_fields_filled=params["include_if_all_fields_filled"] or [],
        exclude_if_any_field_filled=params["exclude_if_any_field_filled"] or [],
        extra_dataframe_fields=fields,
    )
    log.preview("requ√™te SQL utilis√©e", query)
    log.preview("acteurs s√©lectionn√©s", df)
    log.preview("# acteurs par source_id", df.groupby("source_id").size())
    log.preview("# acteurs par acteur_type_id", df.groupby("acteur_type_id").size())

    if df.empty:
        raise ValueError("Aucun acteur trouv√© avec les crit√®res de s√©lection")

    logging.info(log.banner_string("üèÅ R√©sultat final de cette t√¢che"))
    df = cluster_acteurs_df_sort(df)
    log.preview_df_as_markdown("acteurs s√©lectionn√©s", df)

    kwargs["ti"].xcom_push(key="df", value=df)


def cluster_acteurs_db_data_read_acteurs_task(dag: DAG) -> PythonOperator:
    """La t√¢che Airflow qui ne fait que appeler le wrapper"""
    return PythonOperator(
        task_id="cluster_acteurs_db_data_read_acteurs",
        python_callable=cluster_acteurs_db_data_read_acteurs_wrapper,
        dag=dag,
    )
