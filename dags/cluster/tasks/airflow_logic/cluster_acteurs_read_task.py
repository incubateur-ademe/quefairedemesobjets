import logging

from airflow import DAG
from airflow.exceptions import AirflowSkipException
from airflow.operators.python import PythonOperator
from cluster.config.model import ClusterConfig
from cluster.tasks.airflow_logic.task_ids import TASK_CONFIG_CREATE, TASK_SELECTION
from cluster.tasks.business_logic.cluster_acteurs_read.for_clustering import (
    cluster_acteurs_read_for_clustering,
)
from utils import logging_utils as log

logger = logging.getLogger(__name__)


def task_info_get():
    return f"""


    ============================================================
    Description de la tÃ¢che "{TASK_SELECTION}"
    ============================================================

    ðŸ’¡ quoi: va chercher en base de donnÃ©es les acteurs correspondants
        aux critÃ¨res d'inclusion et d'exclusion du DAG
         - ces acteurs "candidats" ne seront pas forcÃ©ment utilisÃ©s
         dans des clusters

    ðŸŽ¯ pourquoi: c'est la donnÃ©e de base dont on a besoin pour le clustering

    ðŸ—ï¸ comment: constructions/execution d'une requÃªte SQL sur la base
        des critrÃ¨res d'inclusion/exclusion
    """


def cluster_acteurs_read_wrapper(**kwargs) -> None:
    logger.info(task_info_get())

    config: ClusterConfig = kwargs["ti"].xcom_pull(
        key="config", task_ids=TASK_CONFIG_CREATE
    )
    log.preview("Config reÃ§ue", config)

    df = cluster_acteurs_read_for_clustering(
        include_source_ids=config.include_source_ids,
        include_acteur_type_ids=config.include_acteur_type_ids,
        include_only_if_regex_matches_nom=config.include_only_if_regex_matches_nom,
        include_if_all_fields_filled=config.include_if_all_fields_filled,
        exclude_if_any_field_filled=config.exclude_if_any_field_filled,
        include_parents_only_if_regex_matches_nom=config.include_parents_only_if_regex_matches_nom,
        fields_protected=config.fields_protected,
        fields_transformed=config.fields_transformed,
    )

    if df.empty:
        raise AirflowSkipException("Aucun orphelin trouvÃ© pour le clustering")

    logging.info(log.banner_string("ðŸ RÃ©sultat final de cette tÃ¢che"))
    log.preview_df_as_markdown("acteurs sÃ©lectionnÃ©s", df)

    kwargs["ti"].xcom_push(key="df", value=df)


def cluster_acteurs_read_task(dag: DAG) -> PythonOperator:
    return PythonOperator(
        task_id=TASK_SELECTION,
        python_callable=cluster_acteurs_read_wrapper,
        dag=dag,
    )
