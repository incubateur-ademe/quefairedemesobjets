import logging

import pandas as pd
from airflow import DAG
from airflow.operators.python import PythonOperator
from cluster.tasks.business_logic.cluster_acteurs_df_sort import cluster_acteurs_df_sort
from cluster.tasks.business_logic.cluster_acteurs_normalize import (
    cluster_acteurs_normalize,
)
from utils import logging_utils as log

logger = logging.getLogger(__name__)


def task_info_get():
    return """


    ============================================================
    Description de la t√¢che "cluster_acteurs_normalize_task"
    ============================================================

    üí° quoi: normalise les valeurs des champs normalize_fields

    üéØ pourquoi: pour accroite les chances de correspondance (soit
    exacte soit fuzzy)

    üèóÔ∏è comment: les normalisations sont appliqu√©es dans l'ordre
    de la UI. Si un champ est sp√©cifi√© dans plusieurs options,
    toutes les normalisations sont appliqu√©es √† la suite.
    """


def cluster_acteurs_normalize_wrapper(**kwargs) -> None:
    logger.info(task_info_get())

    # use xcom to get the params from the previous task
    params = kwargs["ti"].xcom_pull(
        key="params", task_ids="cluster_acteurs_config_validate"
    )
    df: pd.DataFrame = kwargs["ti"].xcom_pull(
        key="df", task_ids="cluster_acteurs_db_data_read_acteurs"
    )
    if df.empty:
        raise ValueError("Pas de donn√©es acteurs r√©cup√©r√©es")

    log.preview("param√®tres re√ßus", params)
    log.preview("acteurs s√©lectionn√©s", df)

    df_norm = cluster_acteurs_normalize(
        df,
        # Par d√©faut si on ne pr√©cise pas de champs,
        # on applique la normalisation basique √† tous les champs
        normalize_fields_basic=params["normalize_fields_basic"] or [],
        normalize_fields_no_words_size1=params["normalize_fields_no_words_size1"] or [],
        normalize_fields_no_words_size2_or_less=params[
            "normalize_fields_no_words_size2_or_less"
        ]
        or [],
        normalize_fields_no_words_size3_or_less=params[
            "normalize_fields_no_words_size3_or_less"
        ]
        or [],
        # Pareil, par d√©faut on applique √† tous les champs
        normalize_fields_order_unique_words=params[
            "normalize_fields_order_unique_words"
        ]
        or [],
    )

    # TODO: shows # uniques before and after per field

    log.preview("acteurs normalis√©s", df_norm)

    logging.info(log.banner_string("üèÅ R√©sultat final de cette t√¢che"))
    df_norm = cluster_acteurs_df_sort(df_norm)
    log.preview_df_as_markdown("acteurs normalis√©s", df_norm)

    # Les XCOM √©tant sp√©cifiques √† une t√¢che on peut pousser
    # le m√™me nom sans risque de collision. Ainsi, pousse le nom "df"
    # et pas "df_norm" pour avoir toujours le nom "df" √† travers
    # toutes les t√¢ches et pas avoir √† se rappeler de la nomenclature
    # des t√¢ches pr√©c√©dentes.
    kwargs["ti"].xcom_push(key="df", value=df_norm)


def cluster_acteurs_normalize_task(dag: DAG) -> PythonOperator:
    """La t√¢che Airflow qui ne fait que appeler le wrapper"""
    return PythonOperator(
        task_id="cluster_acteurs_normalize",
        python_callable=cluster_acteurs_normalize_wrapper,
        dag=dag,
    )
