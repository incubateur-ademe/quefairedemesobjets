from airflow import DAG
from airflow.models.baseoperator import chain
from airflow.models.param import Param
from clustering.tasks.airflow_logic.clustering_config_validate_task import (
    clustering_acteur_config_validate_task,
)
from clustering.tasks.airflow_logic.clustering_db_data_read_acteurs_task import (
    clustering_db_data_read_acteurs_task,
)
from sources.tasks.airflow_logic.operators import default_args
from sources.tasks.business_logic.read_mapping_from_postgres import (
    read_mapping_from_postgres,
)
from utils.airflow_params import airflow_params_dropdown_from_mapping

# On doit initialiser Django avant de pouvoir importer les mod√®les
from utils.django import django_model_fields_attributes_get, django_setup_full

# Oblig√© d'avoir la fonction setup avant l'import des mod√®les
django_setup_full()
from qfdmo.models import Acteur  # noqa: E402

default_args["retries"] = 0

# -------------------------------------------
# Gestion des dropdowns des param√®tres
# -------------------------------------------
# A noter que ce design pattern est a √©viter au maximum
# car le code est execut√© au parsing des fichiers DAG
# selon min_file_process_interval
# https://airflow.apache.org/docs/apache-airflow/stable/configurations-ref.html#config-scheduler-min-file-process-interval
# https://airflow.apache.org/docs/apache-airflow/stable/best-practices.html#top-level-python-code
# En revanche sans cette approche, il va falloir:
# - soit laisser le m√©tier rentrer des param√®tres complexes √† la main
# - soit maintenir des mapping statiques ici
# Ces deux options semblent pires que l'inconv√©nient du top-level code
# sachant que le code execut√© demeure assez l√©g√©

# R√©cup√©ration donn√©es DB
mapping_source_id_by_code = read_mapping_from_postgres(table_name="qfdmo_source")
mapping_acteur_type_id_by_code = read_mapping_from_postgres(
    table_name="qfdmo_acteurtype"
)
# Cr√©ation des dropdowns
dropdown_sources = airflow_params_dropdown_from_mapping(mapping_source_id_by_code)
dropdown_acteur_types = airflow_params_dropdown_from_mapping(
    mapping_acteur_type_id_by_code
)

dropdown_acteur_columns = django_model_fields_attributes_get(Acteur)

with DAG(
    dag_id="clustering_acteur",
    dag_display_name="Clustering - Acteur",
    default_args=default_args,
    description=("Un DAG pour g√©n√©rer des suggestions de clustering pour les acteurs"),
    params={
        "include_source_codes": Param(
            [],
            type="array",
            # La terminologie Airflow n'est pas tr√®s heureuse
            # mais "examples" est bien la fa√ßon de faire des dropdowns
            # voir https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/params.html
            examples=dropdown_sources,
            description_md="""**‚ûï INCLUSION ACTEURS**: seuls ceux qui proviennent
            de ces sources
            (op√©rateur **OU/OR**)""",
        ),
        "include_acteur_type_codes": Param(
            [],
            type="array",
            examples=dropdown_acteur_types,
            description_md="""**‚ûï INCLUSION ACTEURS**: ceux qui sont de ces types
             (op√©rateur **OU/OR**)""",
        ),
        "include_if_all_fields_filled": Param(
            ["code_postal"],
            type="array",
            examples=dropdown_acteur_columns,
            description_md="""**‚ûï INCLUSION ACTEURS**: ceux dont tous ces champs
            sont **remplis**
             exemple: travailler uniquement sur les acteurs avec SIRET
             (op√©rateur **ET/AND**)""",
        ),
        "exclude_if_any_field_filled": Param(
            [],
            type=["null", "array"],
            examples=dropdown_acteur_columns,
            description_md="""**üõë EXCLUSION ACTEURS**: ceux dont n'importe quel
            de ces champs est **rempli**
            exemple: travailler uniquement sur les acteurs SANS SIRET
            (op√©rateur **OU/OR**)""",
        ),
    },
    schedule=None,
) as dag:
    chain(
        clustering_acteur_config_validate_task(dag=dag),
        clustering_db_data_read_acteurs_task(dag=dag),
    )
