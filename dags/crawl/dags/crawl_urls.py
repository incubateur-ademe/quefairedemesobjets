from datetime import datetime

from airflow import DAG
from airflow.models.baseoperator import chain
from airflow.models.param import Param
from crawl.tasks.airflow_logic.candidates.groupby_url_task import (
    crawl_urls_candidates_groupby_url_task,
)
from crawl.tasks.airflow_logic.candidates.read_from_db_task import (
    crawl_urls_candidates_read_from_db_task,
)
from crawl.tasks.airflow_logic.solve.reach_task import crawl_urls_solve_reach_task
from crawl.tasks.airflow_logic.solve.syntax_task import crawl_urls_solve_syntax_task
from crawl.tasks.airflow_logic.suggestions.metadata_task import (
    crawl_urls_suggestions_metadata_task,
)
from crawl.tasks.airflow_logic.suggestions.prepare_task import (
    crawl_urls_suggestions_prepare_task,
)
from crawl.tasks.airflow_logic.suggestions.write_to_db import (
    crawl_urls_suggestions_write_to_db_task,
)

URL_TYPES = [
    "qfdmo_displayedacteur.url",
]
UI_PARAMS_SEPARATOR_SELECTION = r"""

# S√©lection des d'URLs
"""

with DAG(
    dag_id="crawl_urls_suggestions",
    dag_display_name="üîó Crawl - URLs - Suggestions",
    default_args={
        "owner": "airflow",
        "depends_on_past": False,
        # Une date bidon dans le pass√©e pour
        # par que Airflow "attende" que la date
        # soit atteinte
        "start_date": datetime(2025, 1, 1),
        # Notre donn√©e n'√©tant pas versionn√©e dans le temps,
        # faire du catchup n'a pas de sense
        "catchup": False,
        "email_on_failure": False,
        "email_on_retry": False,
        # Les t√¢ches de ce DAG ne devrait pas avoir de probl√®me
        # de perf donc 0 retries par d√©faut
        "retries": 0,
    },
    description=("Un DAG pour parcourir des URLs et sugg√©rer des corrections"),
    tags=["crawl", "acteurs", "url", "suggestions"],
    params={
        "dry_run": Param(
            True,
            type="boolean",
            description_md=f"""üö± Si coch√©, les URLs seront parcourues
            mais les suggestions pas √©crites en base.
            {UI_PARAMS_SEPARATOR_SELECTION}""",
        ),
        "urls_type": Param(
            URL_TYPES[0],
            enum=URL_TYPES,
            description_md="""**üîó Type d'URL** √† parcourir.
            On pourra faire fonctionner le DAG en mode automatique qui
            alterne les diff√©rents types""",
        ),
        "urls_limit": Param(
            None,
            type=["null", "integer"],
            minimum=1,
            description_md="""**üî¢ Nombre d'URLs** √† parcourir.
            Si pas sp√©cifi√© = toutes les URLs""",
        ),
    },
) as dag:
    chain(
        crawl_urls_candidates_read_from_db_task(dag),
        crawl_urls_candidates_groupby_url_task(dag),
        crawl_urls_solve_syntax_task(dag),
        crawl_urls_solve_reach_task(dag),
        crawl_urls_suggestions_metadata_task(dag),
        crawl_urls_suggestions_prepare_task(dag),
        crawl_urls_suggestions_write_to_db_task(dag),
    )
