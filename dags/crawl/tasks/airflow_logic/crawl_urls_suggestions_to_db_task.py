import logging

import crawl.config.tasks as TASKS
from airflow import DAG
from airflow.exceptions import AirflowSkipException
from airflow.operators.python import PythonOperator
from crawl.config.xcom import XCOM_SUGGESTIONS_META, XCOM_SUGGESTIONS_PREP, xcom_pull
from crawl.tasks.business_logic.crawl_urls_suggestions_to_db import (
    crawl_urls_suggestions_write_to_db,
)

logger = logging.getLogger(__name__)


def task_info_get():
    return f"""


    ============================================================
    Description de la tÃ¢che "{TASKS.SUGGESTIONS_PREP}"
    ============================================================

    ðŸ’¡ quoi: on gÃ©nÃ¨re les suggestions (mais on les Ã©crit pas en DB)

    ðŸŽ¯ pourquoi: validation & affichage airflow avant Ã©criture DB

    ðŸ—ï¸ comment: on rÃ©cupÃ¨re les URL traitÃ©s par la tÃ¢che d'avant:
     - si succÃ¨s ET diffÃ©rent: on suggÃ¨re la nouvelle URL
     - si Ã©chec: on suggÃ¨re du EMPTY
    """


def crawl_urls_suggestions_write_to_db_wrapper(params, ti, dag, run_id) -> None:
    logger.info(task_info_get())

    if params["dry_run"] is not False:
        raise AirflowSkipException("Dry run, on s'arrÃªte lÃ ")

    crawl_urls_suggestions_write_to_db(
        metadata=xcom_pull(ti, XCOM_SUGGESTIONS_META),
        suggestions=xcom_pull(ti, XCOM_SUGGESTIONS_PREP),
        identifiant_action=f"dag_id={dag.dag_id}",
        identifiant_execution=f"run_id={run_id}",
    )


def crawl_urls_suggestions_write_to_db_task(dag: DAG) -> PythonOperator:
    return PythonOperator(
        task_id=TASKS.SUGGESTIONS_TO_DB,
        python_callable=crawl_urls_suggestions_write_to_db_wrapper,
        dag=dag,
    )
