{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c30288f",
   "metadata": {},
   "source": [
    "# Dédupliquer à partir d'un excel\n",
    "\n",
    "A partir du fichier excel de cluster dédupliqué validé par Christian, nous créons un acteur chapeau et nous ratachons les acteurs du cluster à ce chapeau\n",
    "\n",
    "## Déclaration des librairies et des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab3dc870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import uuid\n",
    "\n",
    "import pandas as pd\n",
    "from shapely import wkb\n",
    "from shapely.geometry import Point\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "DATABASE_URL = ''\n",
    "INTERFACE_HOST = \"http://localhost:8000\"\n",
    "# Chemin vers le fichier Excel\n",
    "FILE_PATH = '../duplicated_commerce_actors_threhsold_0_8_11_09_2024.xlsx'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c876c097",
   "metadata": {},
   "source": [
    "## Connection à la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae6d5405-0e71-4f1b-9acb-c3ef733c900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the engine\n",
    "engine = create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca7f32b",
   "metadata": {},
   "source": [
    "## Récupération des id des sources ALIAPUR et COREPILE\n",
    "\n",
    "Car on sait par expérience que ces 2 Eco-organismes ont des données plus propre, on préfèrera donc utiliser leur données plutôt que celle des autres Eco-organisme en cas de choix à faire, champ par champ pour créer l'acteur chapeau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fa217ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération des id des sources aliapur et corepile\n",
    "query = \"SELECT id, code FROM qfdmo_source WHERE code IN ('ALIAPUR','COREPILE');\"\n",
    "sources = pd.read_sql_query(query, engine)\n",
    "trusted_sources = ['ALIAPUR','COREPILE']\n",
    "trusted_source_ids = sources[sources['code'].isin(trusted_sources)]['id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aba3b7e",
   "metadata": {},
   "source": [
    "## Gestion du fichier de déduplication\n",
    "\n",
    "On récupère le fichier à dédupliquer localement et on le transforme en dataframe pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06e514ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Lire le fichier Excel et le convertir en DataFrame\n",
    "df = pd.read_excel(FILE_PATH)\n",
    "\n",
    "columns = df.columns\n",
    "\n",
    "grouped_df = df.groupby('cluster_id').apply(lambda x: x.to_dict(\"records\") if not x.empty else [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae961d5",
   "metadata": {},
   "source": [
    "## Compilation des acteurs chapeau\n",
    "\n",
    "- Regroupement des acteurs par cluster\n",
    "- Choix de la valeur à appliquer pour chacun des champs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a3d3c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordonner chaque groupe par ordre de confiance selon la liste trusted_sources : \n",
    "# D'abord la source ALIAPUR, puis COREPILE, puis les autres sources\n",
    "grouped_df = grouped_df.apply( \n",
    "    lambda x: (\n",
    "        sorted(x, key=lambda y: \n",
    "               trusted_source_ids.index(y['source_id']) \n",
    "               if y['source_id'] in trusted_source_ids \n",
    "               else len(trusted_sources)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# print(grouped_df.head())\n",
    "acteurs_chapeau_par_cluster = {}\n",
    "for cluster_id, group in grouped_df.items():\n",
    "    # Pour chacune des colonnes columns\n",
    "    # On prend dans l'ordre la valeur de la première ligne (group) si elle est non nulle\n",
    "    # Puis la valeur de la suivante si elle est non nulle\n",
    "    # etc\n",
    "    combined_row = {}\n",
    "    for column in columns:\n",
    "        for record in group:\n",
    "            if pd.notnull(record[column]) and record[column]:\n",
    "                combined_row[column] = record[column]\n",
    "                break\n",
    "    combined_row['identifiant_unique'] = str(uuid.uuid4())\n",
    "    acteurs_chapeau_par_cluster[cluster_id] = combined_row\n",
    "\n",
    "#acteurs_chapeau_par_cluster = pd.DataFrame(acteurs_chapeau_par_cluster)\n",
    "acteurs_chapeau = acteurs_chapeau_par_cluster.values()\n",
    "acteurs_chapeau_df = pd.DataFrame(acteurs_chapeau)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34336656",
   "metadata": {},
   "source": [
    "## Création des acteurs chapeau en base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "630e3f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fonction qui convertit le champ `location_latlon` en point dans postgis\n",
    "def convert_to_point(latlon_str):\n",
    "    latlon_str = latlon_str.strip('()')\n",
    "    latitude, longitude = map(float, latlon_str.split(','))\n",
    "    return wkb.dumps(Point(longitude, latitude)).hex()\n",
    "\n",
    "# Fonction qui normalise le siret\n",
    "def compute_siret(siret):\n",
    "    if pd.notna(siret):\n",
    "        siret = str(int(siret))\n",
    "        if siret and len(siret) == 14:\n",
    "            return siret\n",
    "    return None\n",
    "\n",
    "# Fonction qui normalise le siret\n",
    "def compute_codepostal(code_postal):\n",
    "    if pd.notna(code_postal):\n",
    "        if isinstance(code_postal, float):\n",
    "            code_postal = str(int(code_postal))\n",
    "        if code_postal and len(code_postal) == 5:\n",
    "            return code_postal\n",
    "        if code_postal and len(code_postal) == 4:\n",
    "            return '0' + code_postal\n",
    "    return None\n",
    "\n",
    "# Application de la transformation de calcue du champ `location`\n",
    "acteurs_chapeau_df['location'] = acteurs_chapeau_df['location_latlon'].apply(\n",
    "    convert_to_point\n",
    ")\n",
    "\n",
    "# Suppression des colonnes inutiles\n",
    "cleaned_acteurs_chapeau_df = acteurs_chapeau_df.drop(\n",
    "    columns=['cluster_id', 'Review', 'location_latlon', 'siren', 'siret'],\n",
    "    errors='ignore'\n",
    ")\n",
    "\n",
    "cleaned_acteurs_chapeau_df[\"siret\"] = acteurs_chapeau_df[\"siret\"].apply(compute_siret)\n",
    "cleaned_acteurs_chapeau_df[\"code_postal\"] = acteurs_chapeau_df[\"code_postal\"].apply(\n",
    "    compute_codepostal\n",
    ")\n",
    "\n",
    "# Write to the database\n",
    "cleaned_acteurs_chapeau_df.to_sql(\n",
    "    'qfdmo_revisionacteur',\n",
    "    engine,\n",
    "    if_exists=\"append\",\n",
    "    index=False,\n",
    "    method=\"multi\",\n",
    "    chunksize=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd3f25c",
   "metadata": {},
   "source": [
    "## Créaction et mise à jour des RevisionActeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a74f63c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster_id, group in grouped_df.items():\n",
    "    for record in group:\n",
    "        # Creation du revision acteur pour chaque acteur à dédupliquer\n",
    "        response = requests.get(\n",
    "            f\"{INTERFACE_HOST}/qfdmo/getorcreate_revisionacteur/\"\n",
    "            f\"{record['identifiant_unique']}\"\n",
    "        )\n",
    "        # Mise à jour du parent_id avec l'identifiant_unique de l'acteur chapeau\n",
    "        parent_id = acteurs_chapeau_par_cluster[cluster_id]['identifiant_unique']\n",
    "        query = f\"\"\"\n",
    "            UPDATE qfdmo_revisionacteur\n",
    "            SET parent_id = '{parent_id}'\n",
    "            WHERE identifiant_unique = '{record['identifiant_unique']}';\n",
    "        \"\"\"\n",
    "        engine.execute(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2ba6d0",
   "metadata": {},
   "source": [
    "# Outils pour tester\n",
    "\n",
    "Supprimer tous les acteurs chapeau qui viennent d'être créés.\n",
    "\n",
    "⚠️ Ne pas utiliser hors de l'environnement de développement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba9bb5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x11c75c2f0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tooling temporaire\n",
    "\n",
    "\n",
    "# supprimer les acteurs chapeau identifié pas cleaned_acteurs_chapeau_df['identifiant_unique']\n",
    "identifiant_uniques = cleaned_acteurs_chapeau_df['identifiant_unique'].tolist()\n",
    "query = f\"UPDATE qfdmo_revisionacteur SET parent_id = NULL WHERE parent_id IN ({', '.join(f\"'{id}'\" for id in identifiant_uniques)});\"\n",
    "engine.execute(query)\n",
    "query = f\"DELETE FROM qfdmo_revisionacteur WHERE identifiant_unique IN ({', '.join(f\"'{id}'\" for id in identifiant_uniques)});\"\n",
    "engine.execute(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfdac29",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- [ ] Récupérer les données des acteurs + revisionacteurs à partir de la base de données \n",
    "- [ ] Pensez à regarder si un des acteurs à dédupliquer a déjà un acteur chapeau "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6097d1c4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
