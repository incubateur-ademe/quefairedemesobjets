{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c30288f",
   "metadata": {},
   "source": [
    "# Dédupliquer à partir d'un excel\n",
    "\n",
    "A partir du fichier excel de cluster dédupliqué validé par Christian, nous créons un acteur chapeau et nous ratachons les acteurs du cluster à ce chapeau\n",
    "\n",
    "## Déclaration des librairies et des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ab3dc870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import uuid\n",
    "\n",
    "import pandas as pd\n",
    "from shapely import wkb\n",
    "from shapely.geometry import Point\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "DATABASE_URL = 'postgresql+psycopg2://…'\n",
    "INTERFACE_HOST = \"http://localhost:8000\"\n",
    "# Chemin vers le fichier Excel\n",
    "FILE_PATH = '../cluster dechetteries - check_similarity_downstream_without_filtering_by_threshold.xlsx'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c876c097",
   "metadata": {},
   "source": [
    "## Connection à la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ae6d5405-0e71-4f1b-9acb-c3ef733c900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the engine\n",
    "engine = create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca7f32b",
   "metadata": {},
   "source": [
    "## Récupération des id des sources ALIAPUR et COREPILE\n",
    "\n",
    "Car on sait par expérience que ces 2 Eco-organismes ont des données plus propre, on préfèrera donc utiliser leur données plutôt que celle des autres Eco-organisme en cas de choix à faire, champ par champ pour créer l'acteur chapeau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5fa217ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération des id des sources aliapur et corepile\n",
    "query_acteur = \"SELECT id, code FROM qfdmo_source WHERE code IN ('ALIAPUR','COREPILE');\"\n",
    "sources = pd.read_sql_query(query_acteur, engine)\n",
    "trusted_sources = ['ALIAPUR','COREPILE']\n",
    "trusted_source_ids = sources[sources['code'].isin(trusted_sources)]['id'].tolist()\n",
    "\n",
    "# Ajouter l'id 0 au début de la liste trusted_source_ids pour doner la priorité\n",
    "# aux acteurs chapeau déjà existant\n",
    "trusted_source_ids.insert(0, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aba3b7e",
   "metadata": {},
   "source": [
    "## Gestion du fichier de déduplication\n",
    "\n",
    "On récupère le fichier à dédupliquer localement et on le transforme en dataframe pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "06e514ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire le fichier Excel et le convertir en DataFrame\n",
    "df = pd.read_excel(FILE_PATH)\n",
    "\n",
    "# On ne récupère ques les clusters d'identifiant_unique, le reste est retrouvé via\n",
    "# la base de données\n",
    "df_clusters = df[['cluster_id', 'identifiant_unique']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69a8bf5",
   "metadata": {},
   "source": [
    "## Récupération des acteurs et revisionacteurs de la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5ec81997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtré par identifiant_unique\n",
    "identifiant_unique = df_clusters['identifiant_unique'].tolist()\n",
    "identifiant_unique_list = [f\"'{i}'\" for i in identifiant_unique]\n",
    "\n",
    "query_acteur = f\"SELECT * FROM qfdmo_acteur WHERE identifiant_unique IN ({','.join(identifiant_unique_list)});\"\n",
    "df_acteur_from_sql = pd.read_sql_query(query_acteur, engine)\n",
    "\n",
    "query_revisionacteur = f\"SELECT * FROM qfdmo_revisionacteur WHERE identifiant_unique IN ({','.join(identifiant_unique_list)});\"\n",
    "df_revisionacteur_from_sql = pd.read_sql_query(query_revisionacteur, engine)\n",
    "\n",
    "# merge acteur et revisionacteur\n",
    "df_acteur_from_sql['parent_id'] = None\n",
    "df_acteur_from_sql.set_index(\"identifiant_unique\", inplace=True)\n",
    "df_revisionacteur_from_sql.set_index(\"identifiant_unique\", inplace=True)\n",
    "\n",
    "# mise à jour avec les données de revisionacteur si elles existent\n",
    "df_acteur_from_sql.update(df_revisionacteur_from_sql)\n",
    "df_acteur_from_sql.reset_index(inplace=True)\n",
    "df_acteur_from_sql['is_parent'] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d19467b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération des parents\n",
    "df_parentacteur_from_sql = pd.DataFrame(\n",
    "    columns=df_acteur_from_sql.columns\n",
    ")\n",
    "df_enfantacteur_from_sql = pd.DataFrame(\n",
    "    columns=df_acteur_from_sql.columns\n",
    ")\n",
    "\n",
    "parent_ids = df_revisionacteur_from_sql['parent_id'].dropna().unique().tolist()\n",
    "parent_id_list = [f\"'{i}'\" for i in parent_ids]\n",
    "if parent_ids:\n",
    "    query_parentacteur = f\"SELECT * FROM qfdmo_revisionacteur WHERE identifiant_unique IN ({','.join(parent_id_list)});\"\n",
    "    df_parentacteur_from_sql = pd.read_sql_query(query_parentacteur, engine)\n",
    "    df_parentacteur_from_sql['source_id'] = 0\n",
    "    df_parentacteur_from_sql['is_parent'] = True\n",
    "\n",
    "    # récupération des enfants des parents pour les inclure dans les clusters\n",
    "    query_enfantacteur = f\"SELECT * FROM qfdmo_revisionacteur WHERE parent_id IN ({','.join(parent_id_list)});\"\n",
    "    df_enfantacteur_from_sql = pd.read_sql_query(query_enfantacteur, engine)\n",
    "    df_enfantacteur_from_sql['is_parent'] = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "fd66309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout du cluster_id dans les acteurs\n",
    "df_acteur_from_sql = df_acteur_from_sql.merge(df_clusters, on='identifiant_unique', how='left')\n",
    "\n",
    "# Ajout du cluster_id dans les parents en inspectant si le cluster des enfant dans df_acteur_from_sql\n",
    "df_parentacteur_from_sql[\"cluster_id\"] = df_parentacteur_from_sql['identifiant_unique'].apply(\n",
    "    lambda x: df_acteur_from_sql[df_acteur_from_sql['parent_id'] == x]['cluster_id'].values[0])\n",
    "\n",
    "# ajout du cluster_id dans les enfants en inspectant le cluster_id de leur parent\n",
    "df_enfantacteur_from_sql[\"cluster_id\"] = df_enfantacteur_from_sql['parent_id'].apply(\n",
    "    lambda identifiant_unique: df_parentacteur_from_sql[df_parentacteur_from_sql['identifiant_unique'] == identifiant_unique]['cluster_id'].values[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae961d5",
   "metadata": {},
   "source": [
    "## Compilation des acteurs chapeau\n",
    "\n",
    "- Regroupement des acteurs par cluster\n",
    "- Choix de la valeur à appliquer pour chacun des champs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3a3d3c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2p/9gsx3n6n4kn4qn8lzv1v8llr0000gn/T/ipykernel_7843/2682940684.py:1: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_acteur_merged = pd.concat([df_acteur_from_sql, df_parentacteur_from_sql, df_enfantacteur_from_sql])\n"
     ]
    }
   ],
   "source": [
    "df_acteur_merged = pd.concat([df_acteur_from_sql, df_parentacteur_from_sql, df_enfantacteur_from_sql])\n",
    "df_acteur_merged.drop_duplicates(subset=['identifiant_unique'], inplace=True)\n",
    "grouped_df = df_acteur_merged.groupby('cluster_id').apply(lambda x: x.to_dict(\"records\") if not x.empty else [])\n",
    "\n",
    "# Ordonner chaque groupe par ordre de confiance selon la liste trusted_sources : \n",
    "# D'abord la source ALIAPUR, puis COREPILE, puis les autres sources\n",
    "grouped_df = grouped_df.apply( \n",
    "    lambda x: (\n",
    "        sorted(x, key=lambda y: \n",
    "               trusted_source_ids.index(y['source_id']) \n",
    "               if y['source_id'] in trusted_source_ids\n",
    "               else len(trusted_sources)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# print(grouped_df.head())\n",
    "acteurchapeau_par_cluster = {}\n",
    "for cluster_id, group in grouped_df.items():\n",
    "    # Pour chacune des colonnes columns\n",
    "    # On prend dans l'ordre la valeur de la première ligne (group) si elle est non nulle\n",
    "    # Puis la valeur de la suivante si elle est non nulle\n",
    "    # etc\n",
    "    combined_row = {}\n",
    "    for column in df_acteur_merged.columns:\n",
    "        for record in group:\n",
    "            if pd.isnull(record[column]) or pd.isna(record[column]) or record[column] == '':\n",
    "                break\n",
    "            combined_row[column] = record[column]\n",
    "\n",
    "    combined_row['identifiant_unique'] = str(uuid.uuid4())\n",
    "    acteurchapeau_par_cluster[cluster_id] = combined_row\n",
    "\n",
    "#acteurs_chapeau_par_cluster = pd.DataFrame(acteurs_chapeau_par_cluster)\n",
    "acteurs_chapeau = acteurchapeau_par_cluster.values()\n",
    "df_acteurchapeau = pd.DataFrame(acteurs_chapeau)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34336656",
   "metadata": {},
   "source": [
    "## Création des acteurs chapeau en base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "630e3f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2649"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suppression des colonnes qui ne sont pas en base de données\n",
    "cleaned_acteurs_chapeau_df = df_acteurchapeau.drop(columns=['is_parent', 'cluster_id'])\n",
    "# Write to the database\n",
    "cleaned_acteurs_chapeau_df.to_sql(\n",
    "    'qfdmo_revisionacteur',\n",
    "    engine,\n",
    "    if_exists=\"append\",\n",
    "    index=False,\n",
    "    method=\"multi\",\n",
    "    chunksize=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd3f25c",
   "metadata": {},
   "source": [
    "## Créaction et mise à jour des RevisionActeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a74f63c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retries = 3\n",
    "from tenacity import retry, wait_fixed, stop_after_attempt, retry_if_exception_type\n",
    "@retry(\n",
    "    wait=wait_fixed(5),\n",
    "    stop=stop_after_attempt(3),\n",
    "    retry=retry_if_exception_type(Exception)\n",
    ")\n",
    "def get_or_create_revisionacteur(identifiant_unique):\n",
    "    response = requests.get(\n",
    "        f\"{INTERFACE_HOST}/qfdmo/getorcreate_revisionacteur/{identifiant_unique}\"\n",
    "    )\n",
    "    if response.status_code >= 400:\n",
    "        raise Exception(f\"Error while getting or creating revisionacteur for {identifiant_unique}\")\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "for cluster_id, group in grouped_df.items():\n",
    "    for record in group:\n",
    "        if record['is_parent']:\n",
    "            continue\n",
    "        # Creation du revision acteur pour chaque acteur à dédupliquer\n",
    "        # TODO : ajouter un retries\n",
    "        response = requests.get(\n",
    "            f\"{INTERFACE_HOST}/qfdmo/getorcreate_revisionacteur/\"\n",
    "            f\"{record['identifiant_unique']}\"\n",
    "        )\n",
    "        # Mise à jour du parent_id avec l'identifiant_unique de l'acteur chapeau\n",
    "        parent_id = acteurchapeau_par_cluster[cluster_id]['identifiant_unique']\n",
    "        query_acteur = f\"\"\"\n",
    "            UPDATE qfdmo_revisionacteur\n",
    "            SET parent_id = '{parent_id}'\n",
    "            WHERE identifiant_unique = '{record['identifiant_unique']}';\n",
    "        \"\"\"\n",
    "        engine.execute(query_acteur)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c949fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove old parent\n",
    "if parent_ids:\n",
    "    query_delete_old_parentacteur = f\"\"\"DELETE FROM qfdmo_revisionacteur WHERE identifiant_unique IN ({','.join(parent_id_list)});\"\"\"\n",
    "    engine.execute(query_delete_old_parentacteur)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2ba6d0",
   "metadata": {},
   "source": [
    "# Outils pour tester\n",
    "\n",
    "Supprimer tous les acteurs chapeau qui viennent d'être créés.\n",
    "\n",
    "⚠️ Ne pas utiliser hors de l'environnement de développement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ba9bb5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x126d13f80>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tooling temporaire\n",
    "\n",
    "\n",
    "# supprimer les acteurs chapeau identifié pas cleaned_acteurs_chapeau_df['identifiant_unique']\n",
    "identifiant_uniques = cleaned_acteurs_chapeau_df['identifiant_unique'].tolist()\n",
    "query_acteur = f\"UPDATE qfdmo_revisionacteur SET parent_id = NULL WHERE parent_id IN ({', '.join(f\"'{id}'\" for id in identifiant_uniques)});\"\n",
    "engine.execute(query_acteur)\n",
    "query_acteur = f\"DELETE FROM qfdmo_revisionacteur WHERE identifiant_unique IN ({', '.join(f\"'{id}'\" for id in identifiant_uniques)});\"\n",
    "engine.execute(query_acteur)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfdac29",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    " - [x] Récupérer les données des acteurs + revisionacteurs à partir de la base de données \n",
    " - [x] Pensez à regarder si un des acteurs à dédupliquer a déjà un acteur chapeau \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6097d1c4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
